{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: torchvision in c:\\users\\umama\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\umama\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached torch-2.6.0-cp311-cp311-win_amd64.whl (204.2 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting YOLO\n",
      "  Using cached yolo-0.3.2-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting awscli (from YOLO)\n",
      "  Using cached awscli-1.37.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting boto3 (from YOLO)\n",
      "  Using cached boto3-1.36.10-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: botocore>=1.7.18 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from YOLO) (1.31.64)\n",
      "Requirement already satisfied: click in c:\\users\\umama\\anaconda3\\lib\\site-packages (from YOLO) (8.1.7)\n",
      "Collecting docker==3.4.0 (from YOLO)\n",
      "  Using cached docker-3.4.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from YOLO) (3.1.3)\n",
      "Collecting keyring==8.7.0 (from YOLO)\n",
      "  Using cached keyring-8.7-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting keyrings.alt (from YOLO)\n",
      "  Using cached keyrings.alt-5.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\umama\\anaconda3\\lib\\site-packages (from YOLO) (2.31.0)\n",
      "Requirement already satisfied: ruamel.yaml in c:\\users\\umama\\anaconda3\\lib\\site-packages (from YOLO) (0.17.21)\n",
      "Requirement already satisfied: tabulate in c:\\users\\umama\\anaconda3\\lib\\site-packages (from YOLO) (0.9.0)\n",
      "Collecting voluptuous (from YOLO)\n",
      "  Using cached voluptuous-0.15.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from docker==3.4.0->YOLO) (1.16.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from docker==3.4.0->YOLO) (0.58.0)\n",
      "Collecting docker-pycreds>=0.3.0 (from docker==3.4.0->YOLO)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "INFO: pip is looking at multiple versions of docker to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting YOLO\n",
      "  Using cached yolo-0.3.1.tar.gz (44 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docker (from YOLO)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pywin32-ctypes in c:\\users\\umama\\anaconda3\\lib\\site-packages (from keyring==8.7.0->YOLO) (0.2.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from docker->YOLO) (305.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from docker->YOLO) (2.0.7)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from botocore>=1.7.18->YOLO) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from botocore>=1.7.18->YOLO) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from requests->YOLO) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from requests->YOLO) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from requests->YOLO) (2024.2.2)\n",
      "Collecting botocore>=1.7.18 (from YOLO)\n",
      "  Using cached botocore-1.36.10-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting docutils<0.17,>=0.10 (from awscli->YOLO)\n",
      "  Using cached docutils-0.16-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from awscli->YOLO)\n",
      "  Using cached s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from awscli->YOLO) (6.0.1)\n",
      "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from awscli->YOLO) (0.4.6)\n",
      "Collecting rsa<4.8,>=3.1.2 (from awscli->YOLO)\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from jinja2->YOLO) (2.1.3)\n",
      "Requirement already satisfied: jaraco.classes in c:\\users\\umama\\anaconda3\\lib\\site-packages (from keyrings.alt->YOLO) (3.2.1)\n",
      "Collecting jaraco.context (from keyrings.alt->YOLO)\n",
      "  Using cached jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from rsa<4.8,>=3.1.2->awscli->YOLO) (0.4.8)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\umama\\anaconda3\\lib\\site-packages (from jaraco.classes->keyrings.alt->YOLO) (10.1.0)\n",
      "Collecting backports.tarfile (from jaraco.context->keyrings.alt->YOLO)\n",
      "  Downloading backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Using cached keyring-8.7-py2.py3-none-any.whl (33 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached awscli-1.37.10-py3-none-any.whl (4.6 MB)\n",
      "Using cached botocore-1.36.10-py3-none-any.whl (13.3 MB)\n",
      "Using cached boto3-1.36.10-py3-none-any.whl (139 kB)\n",
      "Using cached keyrings.alt-5.0.2-py3-none-any.whl (17 kB)\n",
      "Using cached voluptuous-0.15.2-py3-none-any.whl (31 kB)\n",
      "Using cached docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Using cached s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
      "Using cached jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\n",
      "Downloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
      "Building wheels for collected packages: YOLO\n",
      "  Building wheel for YOLO (setup.py): started\n",
      "  Building wheel for YOLO (setup.py): finished with status 'done'\n",
      "  Created wheel for YOLO: filename=yolo-0.3.1-py3-none-any.whl size=51864 sha256=8aa0669defcf5b06f2129873d535e00a86376e44cebdb290b708d48dee25c569\n",
      "  Stored in directory: c:\\users\\umama\\appdata\\local\\pip\\cache\\wheels\\9e\\b2\\6e\\8b0516d47929837cfaedc6df7c02568eabb864a5682d61b462\n",
      "Successfully built YOLO\n",
      "Installing collected packages: voluptuous, rsa, keyring, docutils, backports.tarfile, jaraco.context, docker, botocore, s3transfer, keyrings.alt, boto3, awscli, YOLO\n",
      "  Attempting uninstall: keyring\n",
      "    Found existing installation: keyring 23.13.1\n",
      "    Uninstalling keyring-23.13.1:\n",
      "      Successfully uninstalled keyring-23.13.1\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.18.1\n",
      "    Uninstalling docutils-0.18.1:\n",
      "      Successfully uninstalled docutils-0.18.1\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.64\n",
      "    Uninstalling botocore-1.31.64:\n",
      "      Successfully uninstalled botocore-1.31.64\n",
      "Successfully installed YOLO-0.3.1 awscli-1.37.10 backports.tarfile-1.2.0 boto3-1.36.10 botocore-1.36.10 docker-7.1.0 docutils-0.16 jaraco.context-6.0.1 keyring-8.7 keyrings.alt-5.0.2 rsa-4.7.2 s3transfer-0.11.2 voluptuous-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.7.0 requires botocore<1.31.65,>=1.31.16, but you have botocore 1.36.10 which is incompatible.\n",
      "spyder 5.4.3 requires keyring>=17.0.0, but you have keyring 8.7 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cv\n",
      "  Using cached cv-1.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached cv-1.0.0-py3-none-any.whl (7.3 kB)\n",
      "Installing collected packages: cv\n",
      "Successfully installed cv-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\umama\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.70-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (1.11.4)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (2.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\umama\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\umama\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Downloading ultralytics-8.3.70-py3-none-any.whl (914 kB)\n",
      "   ---------------------------------------- 0.0/914.9 kB ? eta -:--:--\n",
      "   - ------------------------------------- 41.0/914.9 kB 991.0 kB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 92.2/914.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 153.6/914.9 kB 1.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 194.6/914.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 256.0/914.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 307.2/914.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 368.6/914.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 419.8/914.9 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 481.3/914.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 553.0/914.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 583.7/914.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 645.1/914.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 716.8/914.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 778.2/914.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 829.4/914.9 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 880.6/914.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 914.9/914.9 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.70 ultralytics-thop-2.0.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 288.9ms\n",
      "Speed: 12.2ms preprocess, 288.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 221.6ms\n",
      "Speed: 4.4ms preprocess, 221.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 256.6ms\n",
      "Speed: 2.5ms preprocess, 256.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 253.0ms\n",
      "Speed: 4.0ms preprocess, 253.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 277.5ms\n",
      "Speed: 3.8ms preprocess, 277.5ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 278.8ms\n",
      "Speed: 4.2ms preprocess, 278.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 238.5ms\n",
      "Speed: 5.0ms preprocess, 238.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 218.5ms\n",
      "Speed: 3.4ms preprocess, 218.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 224.2ms\n",
      "Speed: 3.0ms preprocess, 224.2ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 244.3ms\n",
      "Speed: 3.5ms preprocess, 244.3ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 231.1ms\n",
      "Speed: 4.0ms preprocess, 231.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 206.0ms\n",
      "Speed: 4.0ms preprocess, 206.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 225.3ms\n",
      "Speed: 5.0ms preprocess, 225.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 226.8ms\n",
      "Speed: 6.0ms preprocess, 226.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 243.0ms\n",
      "Speed: 5.4ms preprocess, 243.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 239.6ms\n",
      "Speed: 5.0ms preprocess, 239.6ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 257.1ms\n",
      "Speed: 6.0ms preprocess, 257.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 255.4ms\n",
      "Speed: 5.0ms preprocess, 255.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 251.0ms\n",
      "Speed: 5.1ms preprocess, 251.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 235.5ms\n",
      "Speed: 4.0ms preprocess, 235.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 222.4ms\n",
      "Speed: 3.0ms preprocess, 222.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 234.9ms\n",
      "Speed: 4.0ms preprocess, 234.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 209.7ms\n",
      "Speed: 3.1ms preprocess, 209.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 242.4ms\n",
      "Speed: 2.4ms preprocess, 242.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 239.1ms\n",
      "Speed: 4.0ms preprocess, 239.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 230.5ms\n",
      "Speed: 4.7ms preprocess, 230.5ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 bottles, 229.2ms\n",
      "Speed: 3.4ms preprocess, 229.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 227.5ms\n",
      "Speed: 3.5ms preprocess, 227.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 246.5ms\n",
      "Speed: 3.5ms preprocess, 246.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 245.4ms\n",
      "Speed: 4.5ms preprocess, 245.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 222.7ms\n",
      "Speed: 4.0ms preprocess, 222.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 246.5ms\n",
      "Speed: 5.0ms preprocess, 246.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 236.4ms\n",
      "Speed: 6.0ms preprocess, 236.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 222.1ms\n",
      "Speed: 4.3ms preprocess, 222.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 250.6ms\n",
      "Speed: 3.0ms preprocess, 250.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 223.9ms\n",
      "Speed: 3.4ms preprocess, 223.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 237.2ms\n",
      "Speed: 4.0ms preprocess, 237.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 238.4ms\n",
      "Speed: 4.5ms preprocess, 238.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 229.1ms\n",
      "Speed: 4.2ms preprocess, 229.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 216.0ms\n",
      "Speed: 5.0ms preprocess, 216.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 240.1ms\n",
      "Speed: 4.2ms preprocess, 240.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 245.6ms\n",
      "Speed: 5.2ms preprocess, 245.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 258.9ms\n",
      "Speed: 4.0ms preprocess, 258.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bottle, 243.9ms\n",
      "Speed: 3.8ms preprocess, 243.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 206.3ms\n",
      "Speed: 3.8ms preprocess, 206.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 194.6ms\n",
      "Speed: 2.4ms preprocess, 194.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 617.1ms\n",
      "Speed: 4.0ms preprocess, 617.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 278.8ms\n",
      "Speed: 6.0ms preprocess, 278.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 513.4ms\n",
      "Speed: 4.0ms preprocess, 513.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vase, 208.5ms\n",
      "Speed: 14.3ms preprocess, 208.5ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 373.7ms\n",
      "Speed: 6.7ms preprocess, 373.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 374.2ms\n",
      "Speed: 6.3ms preprocess, 374.2ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 284.3ms\n",
      "Speed: 14.1ms preprocess, 284.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 296.5ms\n",
      "Speed: 3.2ms preprocess, 296.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 214.8ms\n",
      "Speed: 6.2ms preprocess, 214.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 175.5ms\n",
      "Speed: 4.0ms preprocess, 175.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 223.3ms\n",
      "Speed: 4.5ms preprocess, 223.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 208.8ms\n",
      "Speed: 2.3ms preprocess, 208.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 207.8ms\n",
      "Speed: 4.3ms preprocess, 207.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 173.6ms\n",
      "Speed: 3.3ms preprocess, 173.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 149.8ms\n",
      "Speed: 3.3ms preprocess, 149.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 181.9ms\n",
      "Speed: 6.8ms preprocess, 181.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 183.9ms\n",
      "Speed: 3.5ms preprocess, 183.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 168.4ms\n",
      "Speed: 2.0ms preprocess, 168.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 145.2ms\n",
      "Speed: 2.0ms preprocess, 145.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 210.4ms\n",
      "Speed: 3.0ms preprocess, 210.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 209.1ms\n",
      "Speed: 3.5ms preprocess, 209.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 223.3ms\n",
      "Speed: 6.3ms preprocess, 223.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 240.5ms\n",
      "Speed: 4.0ms preprocess, 240.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 381.2ms\n",
      "Speed: 4.4ms preprocess, 381.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 234.0ms\n",
      "Speed: 6.1ms preprocess, 234.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 196.7ms\n",
      "Speed: 5.0ms preprocess, 196.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 210.2ms\n",
      "Speed: 5.0ms preprocess, 210.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 1 donut, 234.9ms\n",
      "Speed: 8.5ms preprocess, 234.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 226.9ms\n",
      "Speed: 6.3ms preprocess, 226.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 314.1ms\n",
      "Speed: 4.4ms preprocess, 314.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 213.5ms\n",
      "Speed: 6.4ms preprocess, 213.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 264.9ms\n",
      "Speed: 6.2ms preprocess, 264.9ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 232.2ms\n",
      "Speed: 4.1ms preprocess, 232.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 264.3ms\n",
      "Speed: 9.0ms preprocess, 264.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 255.3ms\n",
      "Speed: 5.4ms preprocess, 255.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 229.2ms\n",
      "Speed: 4.0ms preprocess, 229.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 233.1ms\n",
      "Speed: 9.0ms preprocess, 233.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 229.0ms\n",
      "Speed: 8.1ms preprocess, 229.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 228.7ms\n",
      "Speed: 10.4ms preprocess, 228.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 223.3ms\n",
      "Speed: 4.5ms preprocess, 223.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 245.3ms\n",
      "Speed: 5.0ms preprocess, 245.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 232.3ms\n",
      "Speed: 8.8ms preprocess, 232.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 286.3ms\n",
      "Speed: 4.0ms preprocess, 286.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 248.7ms\n",
      "Speed: 10.0ms preprocess, 248.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 241.2ms\n",
      "Speed: 5.0ms preprocess, 241.2ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 243.4ms\n",
      "Speed: 4.3ms preprocess, 243.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 356.8ms\n",
      "Speed: 4.3ms preprocess, 356.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 193.9ms\n",
      "Speed: 14.6ms preprocess, 193.9ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 202.2ms\n",
      "Speed: 4.0ms preprocess, 202.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 233.3ms\n",
      "Speed: 3.0ms preprocess, 233.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 243.7ms\n",
      "Speed: 5.0ms preprocess, 243.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 208.4ms\n",
      "Speed: 3.5ms preprocess, 208.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 236.4ms\n",
      "Speed: 5.0ms preprocess, 236.4ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 237.2ms\n",
      "Speed: 6.5ms preprocess, 237.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 216.6ms\n",
      "Speed: 5.0ms preprocess, 216.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 206.8ms\n",
      "Speed: 6.0ms preprocess, 206.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 donut, 199.1ms\n",
      "Speed: 3.0ms preprocess, 199.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 200.1ms\n",
      "Speed: 5.6ms preprocess, 200.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 202.7ms\n",
      "Speed: 5.0ms preprocess, 202.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 283.1ms\n",
      "Speed: 8.1ms preprocess, 283.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 275.6ms\n",
      "Speed: 25.9ms preprocess, 275.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 417.3ms\n",
      "Speed: 17.4ms preprocess, 417.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 362.3ms\n",
      "Speed: 4.6ms preprocess, 362.3ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 616.9ms\n",
      "Speed: 53.8ms preprocess, 616.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 195.7ms\n",
      "Speed: 9.0ms preprocess, 195.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 215.0ms\n",
      "Speed: 3.0ms preprocess, 215.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 265.2ms\n",
      "Speed: 12.5ms preprocess, 265.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 224.8ms\n",
      "Speed: 3.0ms preprocess, 224.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 227.8ms\n",
      "Speed: 4.0ms preprocess, 227.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 213.6ms\n",
      "Speed: 5.0ms preprocess, 213.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 376.4ms\n",
      "Speed: 5.0ms preprocess, 376.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 220.5ms\n",
      "Speed: 12.7ms preprocess, 220.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 225.7ms\n",
      "Speed: 5.0ms preprocess, 225.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 190.6ms\n",
      "Speed: 5.0ms preprocess, 190.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 181.9ms\n",
      "Speed: 5.2ms preprocess, 181.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 suitcase, 209.6ms\n",
      "Speed: 7.8ms preprocess, 209.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 252.3ms\n",
      "Speed: 6.3ms preprocess, 252.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 237.3ms\n",
      "Speed: 11.0ms preprocess, 237.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 246.5ms\n",
      "Speed: 5.0ms preprocess, 246.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 283.4ms\n",
      "Speed: 5.0ms preprocess, 283.4ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 343.9ms\n",
      "Speed: 8.0ms preprocess, 343.9ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 231.7ms\n",
      "Speed: 6.0ms preprocess, 231.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 222.8ms\n",
      "Speed: 4.0ms preprocess, 222.8ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 206.2ms\n",
      "Speed: 3.0ms preprocess, 206.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 230.2ms\n",
      "Speed: 4.0ms preprocess, 230.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 233.7ms\n",
      "Speed: 4.5ms preprocess, 233.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 253.5ms\n",
      "Speed: 4.1ms preprocess, 253.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 230.6ms\n",
      "Speed: 4.0ms preprocess, 230.6ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 218.6ms\n",
      "Speed: 4.0ms preprocess, 218.6ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 247.4ms\n",
      "Speed: 4.0ms preprocess, 247.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 241.1ms\n",
      "Speed: 6.2ms preprocess, 241.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 232.7ms\n",
      "Speed: 4.0ms preprocess, 232.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 228.1ms\n",
      "Speed: 7.5ms preprocess, 228.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 335.2ms\n",
      "Speed: 5.0ms preprocess, 335.2ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 215.1ms\n",
      "Speed: 5.0ms preprocess, 215.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 221.0ms\n",
      "Speed: 5.0ms preprocess, 221.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 230.8ms\n",
      "Speed: 4.0ms preprocess, 230.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 191.4ms\n",
      "Speed: 4.3ms preprocess, 191.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 201.7ms\n",
      "Speed: 5.0ms preprocess, 201.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 219.3ms\n",
      "Speed: 4.0ms preprocess, 219.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 210.8ms\n",
      "Speed: 8.1ms preprocess, 210.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 267.7ms\n",
      "Speed: 5.0ms preprocess, 267.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.0ms\n",
      "Speed: 7.0ms preprocess, 202.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 204.5ms\n",
      "Speed: 6.0ms preprocess, 204.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 223.9ms\n",
      "Speed: 4.0ms preprocess, 223.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 233.8ms\n",
      "Speed: 6.0ms preprocess, 233.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 211.2ms\n",
      "Speed: 5.1ms preprocess, 211.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 202.4ms\n",
      "Speed: 7.0ms preprocess, 202.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 195.5ms\n",
      "Speed: 4.0ms preprocess, 195.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 216.2ms\n",
      "Speed: 5.2ms preprocess, 216.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 197.4ms\n",
      "Speed: 10.0ms preprocess, 197.4ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 223.0ms\n",
      "Speed: 4.0ms preprocess, 223.0ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 239.9ms\n",
      "Speed: 5.5ms preprocess, 239.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 242.4ms\n",
      "Speed: 4.2ms preprocess, 242.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 260.2ms\n",
      "Speed: 5.0ms preprocess, 260.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 194.8ms\n",
      "Speed: 3.0ms preprocess, 194.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 242.6ms\n",
      "Speed: 118.7ms preprocess, 242.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 214.1ms\n",
      "Speed: 4.4ms preprocess, 214.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 180.4ms\n",
      "Speed: 4.0ms preprocess, 180.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 243.8ms\n",
      "Speed: 9.0ms preprocess, 243.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 178.6ms\n",
      "Speed: 4.0ms preprocess, 178.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 257.5ms\n",
      "Speed: 5.0ms preprocess, 257.5ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 199.2ms\n",
      "Speed: 6.0ms preprocess, 199.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 192.5ms\n",
      "Speed: 5.0ms preprocess, 192.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 229.3ms\n",
      "Speed: 5.4ms preprocess, 229.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 209.6ms\n",
      "Speed: 6.0ms preprocess, 209.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 199.6ms\n",
      "Speed: 4.0ms preprocess, 199.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 214.3ms\n",
      "Speed: 3.7ms preprocess, 214.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 195.8ms\n",
      "Speed: 5.0ms preprocess, 195.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 218.6ms\n",
      "Speed: 14.0ms preprocess, 218.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 209.8ms\n",
      "Speed: 8.0ms preprocess, 209.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 210.8ms\n",
      "Speed: 4.0ms preprocess, 210.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 225.1ms\n",
      "Speed: 5.0ms preprocess, 225.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 231.0ms\n",
      "Speed: 6.0ms preprocess, 231.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 221.2ms\n",
      "Speed: 5.0ms preprocess, 221.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 218.0ms\n",
      "Speed: 9.6ms preprocess, 218.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 208.4ms\n",
      "Speed: 7.1ms preprocess, 208.4ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 217.4ms\n",
      "Speed: 5.0ms preprocess, 217.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 200.3ms\n",
      "Speed: 7.0ms preprocess, 200.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 318.0ms\n",
      "Speed: 5.0ms preprocess, 318.0ms inference, 20.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 190.9ms\n",
      "Speed: 4.0ms preprocess, 190.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 255.6ms\n",
      "Speed: 3.0ms preprocess, 255.6ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 223.5ms\n",
      "Speed: 7.6ms preprocess, 223.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 216.1ms\n",
      "Speed: 5.0ms preprocess, 216.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 232.9ms\n",
      "Speed: 6.5ms preprocess, 232.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 200.0ms\n",
      "Speed: 10.0ms preprocess, 200.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 209.7ms\n",
      "Speed: 5.0ms preprocess, 209.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 222.4ms\n",
      "Speed: 7.9ms preprocess, 222.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 200.8ms\n",
      "Speed: 5.0ms preprocess, 200.8ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 225.6ms\n",
      "Speed: 4.0ms preprocess, 225.6ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 209.2ms\n",
      "Speed: 5.0ms preprocess, 209.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 222.7ms\n",
      "Speed: 8.3ms preprocess, 222.7ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 229.7ms\n",
      "Speed: 5.3ms preprocess, 229.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 251.1ms\n",
      "Speed: 6.0ms preprocess, 251.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 289.7ms\n",
      "Speed: 7.0ms preprocess, 289.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 255.8ms\n",
      "Speed: 5.0ms preprocess, 255.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 236.5ms\n",
      "Speed: 4.0ms preprocess, 236.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 196.2ms\n",
      "Speed: 6.5ms preprocess, 196.2ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 196.2ms\n",
      "Speed: 4.0ms preprocess, 196.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 215.7ms\n",
      "Speed: 6.0ms preprocess, 215.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 249.0ms\n",
      "Speed: 5.0ms preprocess, 249.0ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 230.8ms\n",
      "Speed: 6.0ms preprocess, 230.8ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 355.1ms\n",
      "Speed: 4.0ms preprocess, 355.1ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 297.3ms\n",
      "Speed: 4.0ms preprocess, 297.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 274.8ms\n",
      "Speed: 5.0ms preprocess, 274.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 240.4ms\n",
      "Speed: 6.2ms preprocess, 240.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 213.3ms\n",
      "Speed: 4.0ms preprocess, 213.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 407.0ms\n",
      "Speed: 6.0ms preprocess, 407.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 270.3ms\n",
      "Speed: 8.8ms preprocess, 270.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 319.4ms\n",
      "Speed: 6.5ms preprocess, 319.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 228.3ms\n",
      "Speed: 6.0ms preprocess, 228.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 329.7ms\n",
      "Speed: 13.4ms preprocess, 329.7ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 449.8ms\n",
      "Speed: 6.3ms preprocess, 449.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 257.8ms\n",
      "Speed: 8.0ms preprocess, 257.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 1 donut, 210.2ms\n",
      "Speed: 5.0ms preprocess, 210.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 240.5ms\n",
      "Speed: 4.0ms preprocess, 240.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 279.4ms\n",
      "Speed: 7.0ms preprocess, 279.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 245.1ms\n",
      "Speed: 7.3ms preprocess, 245.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 232.2ms\n",
      "Speed: 7.3ms preprocess, 232.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 248.2ms\n",
      "Speed: 6.0ms preprocess, 248.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 220.1ms\n",
      "Speed: 6.0ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 318.0ms\n",
      "Speed: 5.0ms preprocess, 318.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 170.3ms\n",
      "Speed: 6.0ms preprocess, 170.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 167.7ms\n",
      "Speed: 4.9ms preprocess, 167.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 179.1ms\n",
      "Speed: 2.3ms preprocess, 179.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 172.8ms\n",
      "Speed: 5.0ms preprocess, 172.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 184.5ms\n",
      "Speed: 2.0ms preprocess, 184.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 176.4ms\n",
      "Speed: 4.3ms preprocess, 176.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 155.0ms\n",
      "Speed: 2.0ms preprocess, 155.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 131.7ms\n",
      "Speed: 2.0ms preprocess, 131.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 148.1ms\n",
      "Speed: 2.0ms preprocess, 148.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 152.6ms\n",
      "Speed: 3.4ms preprocess, 152.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 147.1ms\n",
      "Speed: 3.0ms preprocess, 147.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 141.1ms\n",
      "Speed: 2.5ms preprocess, 141.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 157.7ms\n",
      "Speed: 4.4ms preprocess, 157.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 144.2ms\n",
      "Speed: 2.0ms preprocess, 144.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 158.8ms\n",
      "Speed: 3.6ms preprocess, 158.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 153.0ms\n",
      "Speed: 3.7ms preprocess, 153.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 164.1ms\n",
      "Speed: 2.3ms preprocess, 164.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 160.2ms\n",
      "Speed: 3.5ms preprocess, 160.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 137.0ms\n",
      "Speed: 2.5ms preprocess, 137.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")  # Use 'yolov8s.pt' for a more accurate model\n",
    "\n",
    "# Open video stream (0 for webcam, or provide video file path)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run object detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box coordinates\n",
    "            conf = box.conf[0]  # Confidence score\n",
    "            cls = int(box.cls[0])  # Class ID\n",
    "            \n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            label = f\"{model.names[cls]} {conf:.2f}\"\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Object Detection & Tracking\", frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
